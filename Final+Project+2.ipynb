{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165000, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "left = pd.read_csv('/Users/praynaa/Downloads/train_input.csv')\n",
    "right = pd.read_csv('/Users/praynaa/Downloads/train_output.csv')\n",
    "\n",
    "frames = [left, right]\n",
    "joined = pd.concat(frames, axis=1)\n",
    "joined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category = np.where(joined['category'].str.contains('new'), 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No'], \n",
       "      dtype='|S3')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<speaker_1> seaworld ceo steps down amid tanking revenues - company announces undisclosed number of layoffs after volley of public criticism for its treatment of killer whales , underscored in <number> documentary blackfish outsideonline . com </s> <speaker_2> nothing like a little propaganda coupled with a good media campaign to sway public perception . pathetic . </s> <speaker_3> are you saying that the status quo should be upheld , and that maybe , just maybe , seaworld shouldn 't make at least a couple of changes regarding the well - being of their animals and safety of the trainers ? ? </s> </d>\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#or equivalently:\n",
    "#j = pd.merge(left, right) # merges the two datasets\n",
    "\n",
    "joined['conversation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/praynaa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seaworld ceo step amid tank revenu compani ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strickland charger owner dean spano goldman sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iniesta play keepi uppi one leg man youtub com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chappi trailer hugh jackman sci fi comedi hd y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>church satan may get open citi council next me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>godzilla concept art imgur com origin script g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>peopl ever oppos nsa practic edward snowden re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mike smith team canada mask imgur com fuckin c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>interstellar get unexpect twitter review neil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>doc river reaction get technic iggi style amaz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  seaworld ceo step amid tank revenu compani ann...\n",
       "1  strickland charger owner dean spano goldman sa...\n",
       "2  iniesta play keepi uppi one leg man youtub com...\n",
       "3  chappi trailer hugh jackman sci fi comedi hd y...\n",
       "4  church satan may get open citi council next me...\n",
       "5  godzilla concept art imgur com origin script g...\n",
       "6  peopl ever oppos nsa practic edward snowden re...\n",
       "7  mike smith team canada mask imgur com fuckin c...\n",
       "8  interstellar get unexpect twitter review neil ...\n",
       "9  doc river reaction get technic iggi style amaz..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords') #contains the list of irrelevant words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from __future__ import print_function, unicode_literals\n",
    "\n",
    "corpus = []\n",
    "\n",
    "#Cleaning the texts\n",
    "for i in range(0,10):\n",
    "    notconversation = joined['conversation'][i]\n",
    "    conversation = re.sub('<.*?>', ' ', notconversation) #removes all <*>\n",
    "    conversation = re.sub('[^a-zA-Z]', ' ', conversation) #removes all punctuation\n",
    "    conversation = conversation.lower() #sets everything to lowercase\n",
    "    conversation = conversation.split()\n",
    "    \n",
    "    #Stemming (taking the root of the word)\n",
    "    stemmer = PorterStemmer()\n",
    "    conversation = [stemmer.stem(word) for word in conversation if not word in set(stopwords.words('english'))] #removing all words in the stop word list\n",
    "    conversation = ' '.join(conversation)\n",
    "    \n",
    "    corpus.append(conversation)\n",
    "\n",
    "\n",
    "#Stemming (taking the root of the word)\n",
    "corpus = pd.DataFrame(corpus)\n",
    "\n",
    "\n",
    "#Creating bag of words model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
